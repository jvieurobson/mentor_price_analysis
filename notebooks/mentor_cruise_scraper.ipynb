{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28347d79",
   "metadata": {},
   "source": [
    "### 1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba661f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import configparser\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b83b23b3",
   "metadata": {},
   "source": [
    "### 2. Scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0b4963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open file containing rotating proxies.\n",
    "try:\n",
    "    proxies_file = open(r\"C:\\Users\\jonat\\data_projects\\mentors_scraping\\data\\rotating_proxies_list.txt\", \"r\")\n",
    "except FileNotFoundError:\n",
    "    proxies_file_path = r'C:\\Users\\jonat\\data_projects\\mentors_scraping\\data\\rotating_proxies_list.txt'\n",
    "    print(f\"Error: File not found at {proxies_file_path}\")\n",
    "\n",
    "#Set starting page number for scraping.\n",
    "page = 1\n",
    "\n",
    "#Create empty list to append scraped data to.\n",
    "profiles_list = []\n",
    "\n",
    "#Set up loop through proxies file to test and return first responsive proxy.\n",
    "for proxy in proxies_file:\n",
    "\n",
    "    #Send request to webpage.\n",
    "    response = requests.get(url = f'https://mentorcruise.com/mentor/browse/?search=&sort=newest&tagsearch=&price__gt=0&price__lt=1200&tz=&type=&&page={page}', \n",
    "                            proxies = {'http': f\"http://{proxy}\"},\n",
    "                            headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "                                        \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "                                        \"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "                                        )\n",
    "    \n",
    "    #Set condition for responsive proxy.\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        #Create BeautifulSoup object.    \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        #Return HTML structure for all profile data.\n",
    "        profiles = soup.find_all('div', class_ = 'relative box px-7 py-8 transition-all duration-150 mb-12 max-w-screen-lg mx-auto')\n",
    "\n",
    "        #Loop through HTML profile data.\n",
    "        for profile in profiles:\n",
    "            \n",
    "            #Extract name.\n",
    "            try:\n",
    "                name = profile.select_one('h3', class_ = 'title text-2xl has-text-blue font-bold').text.split('\\n')[1]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                name = None\n",
    "\n",
    "            #Extract job_title.\n",
    "            try:\n",
    "                job_title = profile.select_one('span.has-text-blue.text-base.mt-2.inline-block').text.split('\\n')[0]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                job_title = None\n",
    "            \n",
    "            #Extract company.\n",
    "            try:\n",
    "                company = profile.select_one('span.has-text-blue.text-base.mt-2.inline-block').text.split('\\n')[1].split()[1]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                company = None\n",
    "\n",
    "            #Extract rating.\n",
    "            try:\n",
    "                rating = profile.select_one('span.rating-display').text.split()[0]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                rating = None\n",
    "\n",
    "            #Extract num_reviews.\n",
    "            try:\n",
    "                num_reviews = profile.select_one('span.rating-display').text.split()[1][1:]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                num_reviews = None\n",
    "                \n",
    "            #Extract long_description.\n",
    "            try:   \n",
    "                long_description = profile.select_one('div.break-word.mt-4.mb-6.max-w-screen-md.text-sm.leading-6').text.split('\\n')[1]\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                long_description = None\n",
    "\n",
    "            #Extract dollars_month.\n",
    "            try:\n",
    "                dollars_month = profile.select_one('span.price-element.minimize').text.replace('$', '')\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                dollars_month = None\n",
    "\n",
    "            #Extract country.\n",
    "            try:\n",
    "                country = profile.select_one('div.relative.h-full.pb-16 span.text-xl.ml-1.align-middle')['title']\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                country = None\n",
    "\n",
    "            #Extract short_description.\n",
    "            try:\n",
    "                short_description = profile.select_one('div.relative.h-full.pb-16 span.font-medium').text.split('\\n')[1]\n",
    "            except (IndexError, AttributeError):\n",
    "                short_description = None\n",
    "\n",
    "            #Extract tags.\n",
    "            try:\n",
    "                services = profile.select_one('div.flex.space-x-4.cursor-default.inline-block.w-full.py-3.my-5.border-0.border-solid.border-t.border-b.border-gray-200.has-text-blue.text-sm.font-semibold')\n",
    "\n",
    "                service_1 = services.text.split('\\n')[5]\n",
    "                service_2 = services.text.split('\\n')[11] + ' Calls'\n",
    "                service_3 = services.text.split('\\n')[18]\n",
    "                service_4 = services.text.split('\\n')[24]\n",
    "\n",
    "            except (IndexError, AttributeError, TypeError):\n",
    "                service_1 = None\n",
    "                service_2 = None\n",
    "                service_3 = None\n",
    "                service_4 = None\n",
    "\n",
    "            #Append extracted data to dataframe.\n",
    "            profiles_list.append(\n",
    "                [name,\n",
    "                job_title,\n",
    "                company,\n",
    "                rating, \n",
    "                num_reviews,\n",
    "                dollars_month,\n",
    "                country,\n",
    "                short_description,\n",
    "                long_description,\n",
    "                service_1,\n",
    "                service_2,\n",
    "                service_3,\n",
    "                service_4]\n",
    "                ) \n",
    "            \n",
    "        #Pause scraper to avoid having connection aborted by server. \n",
    "        time.sleep(5)\n",
    "\n",
    "        #Increment page number by 1 to scrape next page.\n",
    "        page += 1\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    #Assign condition to stop scraper at the very last page where the 'next' button is not found.\n",
    "    if not soup.find('a', class_ = 'border-t-2 border-transparent pt-4 pl-1 inline-flex items-center text-sm font-medium text-gray-500 hover:text-gray-700 hover:border-gray-300'):\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b17c7a8f",
   "metadata": {},
   "source": [
    "### 3. Write to dataframe, rename columns, and re-format datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b2f64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to dataframe and rename columns.\n",
    "profiles_df = pd.DataFrame(profiles_list, columns = ['name', 'job_title', 'company', 'rating', 'num_reviews', 'dollars_month', 'country', 'short_description', 'long_description', 'service_1', 'service_2', 'service_3', 'service_4'])\n",
    "\n",
    "#Re-format datatypes.\n",
    "profiles_df['rating'] = profiles_df['rating'].fillna(0).astype('float')\n",
    "profiles_df['num_reviews'] = profiles_df['num_reviews'].fillna(0).astype('float')\n",
    "profiles_df['dollars_month'] = profiles_df['dollars_month'].fillna(0).astype('int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3640c9d4",
   "metadata": {},
   "source": [
    "### 4. Write to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88ba8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df.to_csv('..\\data\\mentors_profiles.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a891e66",
   "metadata": {},
   "source": [
    "### 5. Write to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6e98d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup ini file and assign variables to authenticate connection.\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "#access database authentication data.\n",
    "host = config['mysql']['host']\n",
    "user = config['mysql']['user']\n",
    "password = config['mysql']['password']\n",
    "database = config['mysql']['database']\n",
    "\n",
    "#create an sqllchemy engine object to authenticate connection.\n",
    "engine = sqlalchemy.create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database}')\n",
    "\n",
    "#write the DataFrame to database.\n",
    "profiles_df.to_sql(name='mentors_profiles', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mentors_scraping)",
   "language": "python",
   "name": "mentors_scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
